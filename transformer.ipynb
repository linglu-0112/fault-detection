{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import math\n",
    "import numpy as np\n",
    "from numpy import linalg as LA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# download the data here: https://doi.org/10.7910/DVN/6C3JR1\n",
    "\n",
    "direc = \"../input/tennessee-eastman-process-simulation-dataset/\"\n",
    "#direc = './'\n",
    "\n",
    "train_normal_path = direc+'TEP_FaultFree_Training.RData'\n",
    "train_faulty_path = direc+'TEP_Faulty_Training.RData'\n",
    "\n",
    "test_normal_path = direc+'TEP_FaultFree_Testing.RData'\n",
    "test_faulty_path = direc+'TEP_Faulty_Testing.RData'\n",
    "\n",
    "train_normal_complete = pyreadr.read_r(train_normal_path)['fault_free_training']\n",
    "#train_faulty_complete = pyreadr.read_r(train_fault_path)['faulty_training']\n",
    "\n",
    "#test_normal_complete = pyreadr.read_r(test_normal_path)['fault_free_testing']\n",
    "test_faulty_complete = pyreadr.read_r(test_faulty_path)['faulty_testing']\n",
    "\n",
    "cols = train_normal_complete.columns[3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.current_device(),torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49920,)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.fromfile('./data/d00.dat', dtype=np.float32, sep='   ')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "960.0"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "49920/52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(error=0, unit=[0], is_train=True):\n",
    "    \"\"\"\n",
    "    Args:p\n",
    "        error (int): The index of error, 0 means normal data\n",
    "        is_train (bool): Read train or test data\n",
    "    Returns:\n",
    "        units' data\n",
    "    \"\"\"\n",
    "\n",
    "    if is_train:\n",
    "        suffix = '.dat'\n",
    "    else:\n",
    "        suffix = '_te.dat'\n",
    "    fi = './data/d{:02d}{}'.format(error, suffix)\n",
    "    data = np.fromfile(fi, dtype=np.float32, sep='   ')\n",
    "\n",
    "    if fi == './data/d00.dat':\n",
    "        # data = data.reshape(-1, 500).T\n",
    "        data = data.reshape(-1, 52)\n",
    "        data = data[:, unit]  #获取特定列的元素\n",
    "    else:\n",
    "        data = data.reshape(-1, 52)\n",
    "        data = data[:, unit]\n",
    "    # if not is_train:\n",
    "    #     data = data[160: ]\n",
    "    return data, np.ones(data.shape[0], np.float32) * error  #获取数据以及标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_data(unit):\n",
    "    train_data, _ = read_data(error=0, unit=unit, is_train=True)\n",
    "    train_data = preprocessing.StandardScaler().fit_transform(train_data)\n",
    "    return train_data  #训练数据归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_data(unit):\n",
    "    test_data = []\n",
    "    for i in range(22):\n",
    "        data, _ = read_data(error=i, unit=unit, is_train=False)\n",
    "        test_data.append(data)\n",
    "    test_data = np.concatenate(test_data) #拉成长度为[22*960,unit_size]\n",
    "    train_data, _ = read_data(error=0, unit=unit, is_train=True)\n",
    "    scaler = preprocessing.StandardScaler().fit(train_data)\n",
    "    return test_data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(960, 4)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = get_test_data([0,1,2,3])\n",
    "test.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## global-local-transformer-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbedddingModel(nn.Module):\n",
    "    def __init__(self, unit_len=[]):\n",
    "        super(EmbedddingModel, self).__init__()\n",
    "        self.unit_len1 = unit_len[0]\n",
    "        self.unit_len2 = unit_len[1]\n",
    "        self.unit_len3 = unit_len[2]\n",
    "        self.unit_len4 = unit_len[3]\n",
    "        self.unit_len5 = unit_len[4]\n",
    "\n",
    "        self.embed1 = nn.Sequential(\n",
    "            nn.Linear(self.unit_len1, 64, bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Linear(64, 16, bias=True)\n",
    "        )\n",
    "        self.nonlinear1 = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.Linear(16, 64, bias=True)\n",
    "        )\n",
    "\n",
    "        self.embed2 = nn.Sequential(\n",
    "            nn.Linear(self.unit_len2, 64, bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Linear(64, 16, bias=True)\n",
    "        )\n",
    "        self.nonlinear2 = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.Linear(16, 64, bias=True)\n",
    "        )\n",
    "\n",
    "        self.embed3 = nn.Sequential(\n",
    "            nn.Linear(self.unit_len3, 64, bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64),\n",
    "             \n",
    "            nn.Linear(64, 16, bias=True)\n",
    "        )\n",
    "        self.nonlinear3 = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.Linear(16, 64, bias=True)\n",
    "        )\n",
    "\n",
    "        self.embed4 = nn.Sequential(\n",
    "            nn.Linear(self.unit_len4, 64, bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64),\n",
    "              \n",
    "            nn.Linear(64, 16, bias=True)\n",
    "        )\n",
    "        self.nonlinear4 = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.Linear(16, 64, bias=True)\n",
    "        )\n",
    "\n",
    "        self.embed5 = nn.Sequential(\n",
    "            nn.Linear(self.unit_len5, 64, bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64),\n",
    "              \n",
    "            nn.Linear(64, 16, bias=True)\n",
    "        )\n",
    "        self.nonlinear5 = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.Linear(16, 64, bias=True)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x1, x2, x3, x4, x5):\n",
    "        h1 = self.embed1(x1)\n",
    "        y1 = self.nonlinear1(h1)\n",
    "        h2 = self.embed2(x2)\n",
    "        y2 = self.nonlinear2(h2)\n",
    "        h3 = self.embed3(x3)\n",
    "        y3 = self.nonlinear3(h3)\n",
    "        h4 = self.embed4(x4)\n",
    "        y4 = self.nonlinear4(h4)\n",
    "        h5 = self.embed5(x5)\n",
    "        y5 = self.nonlinear5(h5)\n",
    "        hidden_state = torch.cat((h1, h2, h3, h4, h5), dim=1)  \n",
    "        src = torch.stack((y1, y2, y3, y4, y5), dim=0)  \n",
    "        return hidden_state, src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "T1 = torch.tensor([[1, 2, 3],\n",
    "        \t\t[4, 5, 6],\n",
    "        \t\t[7, 8, 9]])\n",
    "T2 = torch.tensor([[10, 20, 30],\n",
    "        \t\t[40, 50, 60],\n",
    "        \t\t[70, 80, 90]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1,  2,  3],\n",
       "         [10, 20, 30]],\n",
       "\n",
       "        [[ 4,  5,  6],\n",
       "         [40, 50, 60]],\n",
       "\n",
       "        [[ 7,  8,  9],\n",
       "         [70, 80, 90]]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.stack((T1,T2),dim=1)\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.embed = EmbedddingModel([8, 7, 6, 7, 5])\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=64, nhead=8, dim_feedforward=1024, dropout=0.01,\n",
    "                                                        activation=\"relu\")\n",
    "        self.encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=6)\n",
    "        self.avg1 = nn.Linear(64, 4)\n",
    "        self.linear1 = nn.Linear(4, 8, bias=True)\n",
    "        self.linear2 = nn.Linear(4, 7, bias=True)\n",
    "        self.linear3 = nn.Linear(4, 6, bias=True)\n",
    "        self.linear4 = nn.Linear(4, 7, bias=True)\n",
    "        self.linear5 = nn.Linear(4, 5, bias=True)\n",
    "\n",
    "\n",
    "    def forward(self, x1, x2, x3, x4, x5):\n",
    "        hidden_state, src = self.embed(x1, x2, x3, x4, x5)\n",
    "        memory = self.encoder(src)  \n",
    "        memory = self.avg1(memory.permute(1, 0, 2)) # torch.permute()进行维度换位\n",
    "        memory = memory.permute(1, 0, 2)  \n",
    "        hidden_fea1, hidden_fea2, hidden_fea3, hidden_fea4, hidden_fea5 = torch.chunk(memory, 8, dim=0) #(1,500,4)\n",
    "        hidden_fea1 = torch.squeeze(hidden_fea1)  \n",
    "        hidden_fea2 = torch.squeeze(hidden_fea2)\n",
    "        hidden_fea3 = torch.squeeze(hidden_fea3)\n",
    "        hidden_fea4 = torch.squeeze(hidden_fea4)\n",
    "        hidden_fea5 = torch.squeeze(hidden_fea5)\n",
    "        out = torch.cat((hidden_fea1, hidden_fea2, hidden_fea3, hidden_fea4, hidden_fea5),dim=1) #全局特征(500,20)\n",
    "        fea1 = self.linear1(hidden_fea1) \n",
    "        fea2 = self.linear2(hidden_fea2)\n",
    "        fea3 = self.linear3(hidden_fea3)\n",
    "        fea4 = self.linear4(hidden_fea4)\n",
    "        fea5 = self.linear5(hidden_fea5)\n",
    "        decoder_out = torch.cat((fea1, fea2, fea3, fea4, fea5), dim=1) \n",
    "        return decoder_out, out, hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2, 3])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position = torch.randn(2,4,3)\n",
    "position = position.permute(1,0,2)\n",
    "position.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    #Implement the PE function\n",
    "\n",
    "    def __init__(self, max_len, d_model ):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "\n",
    "        # Compute the positional encodings once in log space.\n",
    "        if d_model%2 ==0:\n",
    "            pe = torch.zeros(max_len, d_model)\n",
    "            position = torch.arange(0, max_len).unsqueeze(1) #在维度1上增加一个维度,变成2维\n",
    "            div_term = torch.exp(torch.arange(0, d_model, 2) *\n",
    "                                -(math.log(10000.0) / d_model))\n",
    "            pe[:, 0::2] = torch.sin(position * div_term)  #传统SCPE公式\n",
    "            pe[:, 1::2] = torch.cos(position * div_term)\n",
    "            pe = pe.unsqueeze(0)\n",
    "        if d_model%2 ==1:\n",
    "            pe = torch.zeros(max_len, d_model+1)\n",
    "            position = torch.arange(0, max_len).unsqueeze(1)\n",
    "            div_term = torch.exp(torch.arange(0, d_model, 2) *\n",
    "                                -(math.log(10000.0) / d_model))\n",
    "            pe[:, 0::2] = torch.sin(position * div_term)\n",
    "            pe[:, 1::2] = torch.cos(position * div_term)\n",
    "            pe = pe[:,:d_model]\n",
    "            pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.permute(x,(1,0,2)) \n",
    "        z = self.pe[:, :x.size(1)].clone().detach()\n",
    "        x = x + z     #对x进行位置编码\n",
    "        return x.permute(1,0,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mDocstring:\u001b[0m\n",
      "chunk(input, chunks, dim=0) -> List of Tensors\n",
      "\n",
      "Attempts to split a tensor into the specified number of chunks. Each chunk is a view of\n",
      "the input tensor.\n",
      "\n",
      "\n",
      ".. note::\n",
      "\n",
      "    This function may return less then the specified number of chunks!\n",
      "\n",
      ".. seealso::\n",
      "\n",
      "    :func:`torch.tensor_split` a function that always returns exactly the specified number of chunks\n",
      "\n",
      "If the tensor size along the given dimesion :attr:`dim` is divisible by :attr:`chunks`,\n",
      "all returned chunks will be the same size.\n",
      "If the tensor size along the given dimension :attr:`dim` is not divisible by :attr:`chunks`,\n",
      "all returned chunks will be the same size, except the last one.\n",
      "If such division is not possible, this function may return less\n",
      "than the specified number of chunks.\n",
      "\n",
      "Arguments:\n",
      "    input (Tensor): the tensor to split\n",
      "    chunks (int): number of chunks to return\n",
      "    dim (int): dimension along which to split the tensor\n",
      "\n",
      "Example::\n",
      "    >>> torch.arange(11).chunk(6)\n",
      "    (tensor([0, 1]),\n",
      "     tensor([2, 3]),\n",
      "     tensor([4, 5]),\n",
      "     tensor([6, 7]),\n",
      "     tensor([8, 9]),\n",
      "     tensor([10]))\n",
      "    >>> torch.arange(12).chunk(6)\n",
      "    (tensor([0, 1]),\n",
      "     tensor([2, 3]),\n",
      "     tensor([4, 5]),\n",
      "     tensor([6, 7]),\n",
      "     tensor([8, 9]),\n",
      "     tensor([10, 11]))\n",
      "    >>> torch.arange(13).chunk(6)\n",
      "    (tensor([0, 1, 2]),\n",
      "     tensor([3, 4, 5]),\n",
      "     tensor([6, 7, 8]),\n",
      "     tensor([ 9, 10, 11]),\n",
      "     tensor([12]))\n",
      "\u001b[1;31mType:\u001b[0m      builtin_function_or_method\n"
     ]
    }
   ],
   "source": [
    "? torch.chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerPe(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TransformerPe, self).__init__()\n",
    "        self.embed = EmbedddingModel([8, 7, 6, 7, 5])\n",
    "        self.PE = PositionalEncoding(5, 5)\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=69, nhead=3, dim_feedforward=1024, dropout=0.01,\n",
    "                                                        activation=\"relu\")                                          #注意d_model和nhead的维度一致\n",
    "        self.encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=6)\n",
    "        self.avg1 = nn.Linear(69, 4)\n",
    "        self.linear1 = nn.Linear(4, 8, bias=True)\n",
    "        self.linear2 = nn.Linear(4, 7, bias=True)\n",
    "        self.linear3 = nn.Linear(4, 6, bias=True)\n",
    "        self.linear4 = nn.Linear(4, 7, bias=True)\n",
    "        self.linear5 = nn.Linear(4, 5, bias=True)\n",
    "\n",
    "\n",
    "    def forward(self, x1, x2, x3, x4, x5):\n",
    "        hidden_state, src = self.embed(x1, x2, x3, x4, x5)\n",
    "        src_pe = self.PE(src)\n",
    "        memory = self.encoder(src_pe) #(5,500,128)\n",
    "        memory = self.avg1(memory.permute(1, 0, 2))\n",
    "        memory = memory.permute(1, 0, 2)\n",
    "        hidden_fea1, hidden_fea2, hidden_fea3, hidden_fea4, hidden_fea5 = torch.chunk(memory, 8, dim=0)\n",
    "        hidden_fea1 = torch.squeeze(hidden_fea1)\n",
    "        hidden_fea2 = torch.squeeze(hidden_fea2)\n",
    "        hidden_fea3 = torch.squeeze(hidden_fea3)\n",
    "        hidden_fea4 = torch.squeeze(hidden_fea4)\n",
    "        hidden_fea5 = torch.squeeze(hidden_fea5)\n",
    "        out = torch.cat((hidden_fea1, hidden_fea2, hidden_fea3, hidden_fea4, hidden_fea5),dim=1) #全局特征\n",
    "        fea1 = self.linear1(hidden_fea1)\n",
    "        fea2 = self.linear2(hidden_fea2)\n",
    "        fea3 = self.linear3(hidden_fea3)\n",
    "        fea4 = self.linear4(hidden_fea4)\n",
    "        fea5 = self.linear5(hidden_fea5)\n",
    "        decoder_out = torch.cat((fea1, fea2, fea3, fea4, fea5), dim=1) #重构输出\n",
    "        return decoder_out, out, hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OPE(nn.Module):\n",
    "    #Implement the OPE function\n",
    "\n",
    "    def __init__(self, max_len, d_model ):\n",
    "        super(OPE, self).__init__()\n",
    "\n",
    "        c = np.zeros((d_model, d_model))\n",
    "        for i in range(d_model):\n",
    "            for j in range(d_model):\n",
    "                c[i,j] = 0.9**np.abs(i-j)\n",
    "        np.set_printoptions(precision=4)\n",
    "        w, v = LA.eig(c)\n",
    "        pe = np.zeros((max_len, d_model-1))\n",
    "        for i in range(max_len):\n",
    "            pe[i,:] = v[i,1:]    \n",
    "        pe = torch.unsqueeze(torch.from_numpy(pe),0) \n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.permute(x,(1,0,2)) \n",
    "        z = self.pe[:, :x.size(1)].clone().detach()\n",
    "        x = x + z      \n",
    "        return x.permute(1,0,2).to(torch.float32)  #(5,500,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerPE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TransformerPE, self).__init__()\n",
    "        self.embed = EmbedddingModel([8, 7, 6, 7, 5])\n",
    "        self.PE = OPE(5, 65)\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=64, nhead=8, dim_feedforward=1024, dropout=0.01,\n",
    "                                                        activation=\"relu\")                                          #注意d_model和nhead的维度一致\n",
    "        self.encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=6)\n",
    "        self.avg1 = nn.Linear(64, 4)\n",
    "        self.linear1 = nn.Linear(4, 8, bias=True)\n",
    "        self.linear2 = nn.Linear(4, 7, bias=True)\n",
    "        self.linear3 = nn.Linear(4, 6, bias=True)\n",
    "        self.linear4 = nn.Linear(4, 7, bias=True)\n",
    "        self.linear5 = nn.Linear(4, 5, bias=True)\n",
    "\n",
    "\n",
    "    def forward(self, x1, x2, x3, x4, x5):\n",
    "        hidden_state, src = self.embed(x1, x2, x3, x4, x5)\n",
    "        src_pe = self.PE(src)\n",
    "        memory = self.encoder(src_pe) #(5,500,128)\n",
    "        memory = self.avg1(memory.permute(1, 0, 2))\n",
    "        memory = memory.permute(1, 0, 2)\n",
    "        hidden_fea1, hidden_fea2, hidden_fea3, hidden_fea4, hidden_fea5 = torch.chunk(memory, 8, dim=0)\n",
    "        hidden_fea1 = torch.squeeze(hidden_fea1)\n",
    "        hidden_fea2 = torch.squeeze(hidden_fea2)\n",
    "        hidden_fea3 = torch.squeeze(hidden_fea3)\n",
    "        hidden_fea4 = torch.squeeze(hidden_fea4)\n",
    "        hidden_fea5 = torch.squeeze(hidden_fea5)\n",
    "        out = torch.cat((hidden_fea1, hidden_fea2, hidden_fea3, hidden_fea4, hidden_fea5),dim=1) \n",
    "        fea1 = self.linear1(hidden_fea1)\n",
    "        fea2 = self.linear2(hidden_fea2)\n",
    "        fea3 = self.linear3(hidden_fea3)\n",
    "        fea4 = self.linear4(hidden_fea4)\n",
    "        fea5 = self.linear5(hidden_fea5)\n",
    "        decoder_out = torch.cat((fea1, fea2, fea3, fea4, fea5), dim=1) \n",
    "        return decoder_out, out, hidden_state"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.optim import lr_scheduler\n",
    "# from model import TransformerPE\n",
    "# from utils import get_train_data, get_test_data\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model = TransformerPE()\n",
    "    model.to(device)\n",
    "    Epoch = 1800\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.002, betas=(0.9, 0.99), eps=1e-08, weight_decay=0.0001)  # alt+enter\n",
    "    scheduler = lr_scheduler.MultiStepLR(optimizer, [500], 0.5)\n",
    "    criterion = nn.MSELoss()\n",
    "    model.train()\n",
    "    epoches = []\n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "\n",
    "    for epoch in range(Epoch):\n",
    "        running_loss = 0.0\n",
    "        optimizer.zero_grad()\n",
    "        decoder_out, out, _ = model(train_data_unit1, train_data_unit2, train_data_unit3, train_data_unit4,train_data_unit5)\n",
    "        loss = criterion(decoder_out, train_data)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if (epoch + 1) % 50 == 0:\n",
    "            print('epoch_{}'.format(epoch+1))\n",
    "            print('training_loss:{}'.format(running_loss))\n",
    "            epoches.append(epoch)\n",
    "            train_loss.append(running_loss)\n",
    "            #保存模型参数\n",
    "            base_path = \"./TE/model/\"\n",
    "            if not os.path.exists(base_path):\n",
    "                os.makedirs(base_path)\n",
    "            torch.save(model.state_dict(),os.path.join(base_path, \"transformer_para_{}\".format(epoch + 1)))\n",
    "            # model.load_state_dict(\n",
    "            #     torch.load(os.path.join(base_path, \"transformer_para_{}\".format(epoch + 1))))\n",
    "            \n",
    "            model.eval()\n",
    "            running_loss_0 = 0.0\n",
    "            with torch.no_grad():\n",
    "                decoder_out, out, hidden_state = model(test_data_unit1, test_data_unit2, test_data_unit3, test_data_unit4, test_data_unit5)\n",
    "                loss = criterion(decoder_out, test_data)\n",
    "                running_loss_0 += loss.item()\n",
    "                test_loss.append(running_loss_0)\n",
    "                print('testing_loss:{}'.format(loss))\n",
    "                \n",
    "            global_fea = out.detach().cpu().numpy()\n",
    "            local_fea = hidden_state.detach().cpu().numpy()\n",
    "            #print(local_fea.shape),(21120,128)\n",
    "            mat1 = {'fea_test': global_fea.T}\n",
    "            mat2 = {'fea_test': local_fea.T}\n",
    "            save_path = \"./TE/feature/\"\n",
    "            if not os.path.exists(save_path):\n",
    "                os.makedirs(save_path)\n",
    "            sio.savemat(os.path.join(save_path,\"fea_glo_{}.mat\".format(epoch + 1)), mat1)\n",
    "            sio.savemat(os.path.join(save_path,\"fea_loc_{}.mat\".format(epoch + 1)), mat2)\n",
    "            # print(\"testing is finished!\")\n",
    "\n",
    "\n",
    "    print(\"time span: %.4f s\" % (time.time() - start))\n",
    "    # plt.plot(epoches, train_loss, color='r', label='train loss')\n",
    "    plt.figure()\n",
    "    plt.plot(epoches, test_loss, color='b', label='test loss')\n",
    "    plt.figure()\n",
    "    plt.plot(epoches, train_loss, color='r', label='train_loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    model = TransformerPE()\n",
    "    model.to(device)\n",
    "\n",
    "    base_path = \"./TE/model/\"\n",
    "    model.load_state_dict(\n",
    "        torch.load(os.path.join(base_path, \"transformer_para_{}\".format(1800))))\n",
    "    # model.load_state_dict(torch.load(\"./TE/transformer_para_1800\"))\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        decoder_out, out, hidden_state = model(test_data_unit1, test_data_unit2, test_data_unit3, test_data_unit4, test_data_unit5)\n",
    "        n = decoder_out - test_data\n",
    " \n",
    "        \n",
    "    global_fea = out.detach().cpu().numpy()\n",
    "    local_fea = hidden_state.detach().cpu().numpy()\n",
    "    res = n.detach().cpu().numpy()\n",
    "\n",
    "    mat1 = {'fea_test': global_fea.T}\n",
    "    mat2 = {'fea_test': local_fea.T}\n",
    "    mat3 = {'res_test': res.T}\n",
    "\n",
    "\n",
    "    save_path = \"./TE/feature/222/\"\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    sio.savemat(os.path.join(save_path,\"fea_glo.mat\"), mat1)\n",
    "    sio.savemat(os.path.join(save_path,\"fea_loc.mat\"), mat2)\n",
    "    sio.savemat(os.path.join(save_path,\"res.mat\"), mat3)\n",
    "  \n",
    "    print('finishing!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    start = time.time()\n",
    "\n",
    "    unit1 = [0, 1, 2, 3, 41, 42, 43, 44]\n",
    "    unit2 = [5, 6, 7, 8, 20, 50, 51]\n",
    "    unit3 = [10, 11, 12, 13, 21, 47]\n",
    "    unit4 = [14, 15, 16, 17, 18, 48, 49]\n",
    "    unit5 = [4, 9, 19, 45, 46]\n",
    "    unit_list = [unit1, unit2, unit3, unit4, unit5]\n",
    "    unit_variables = unit1+unit2+unit3+unit4+unit5\n",
    "    unit_variables = [i+1 for i in unit_variables]\n",
    "    unit_len = [8, 7, 6, 7, 5]\n",
    "\n",
    "    train_data_unit1 = get_train_data(unit1)\n",
    "    train_data_unit1 = torch.from_numpy(train_data_unit1)\n",
    "    train_data_unit2 = get_train_data(unit2)\n",
    "    train_data_unit2 = torch.from_numpy(train_data_unit2)\n",
    "    train_data_unit3 = get_train_data(unit3)\n",
    "    train_data_unit3 = torch.from_numpy(train_data_unit3)\n",
    "    train_data_unit4 = get_train_data(unit4)\n",
    "    train_data_unit4 = torch.from_numpy(train_data_unit4)\n",
    "    train_data_unit5 = get_train_data(unit5)\n",
    "    train_data_unit5 = torch.from_numpy(train_data_unit5)\n",
    "    train_data = torch.cat((train_data_unit1, train_data_unit2, train_data_unit3, train_data_unit4, train_data_unit5),dim=1)\n",
    "\n",
    "    test_data_unit1 = get_test_data(unit1)\n",
    "    test_data_unit1 = torch.from_numpy(test_data_unit1)\n",
    "    test_data_unit2 = get_test_data(unit2)\n",
    "    test_data_unit2 = torch.from_numpy(test_data_unit2)\n",
    "    test_data_unit3 = get_test_data(unit3)\n",
    "    test_data_unit3 = torch.from_numpy(test_data_unit3)\n",
    "    test_data_unit4 = get_test_data(unit4)\n",
    "    test_data_unit4 = torch.from_numpy(test_data_unit4)\n",
    "    test_data_unit5 = get_test_data(unit5)\n",
    "    test_data_unit5 = torch.from_numpy(test_data_unit5)\n",
    "    test_data = torch.cat((test_data_unit1, test_data_unit2, test_data_unit3, test_data_unit4, test_data_unit5),dim=1)\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    train_data = train_data.to(device)\n",
    "    train_data_unit1 = train_data_unit1.to(device)\n",
    "    train_data_unit2 = train_data_unit2.to(device)\n",
    "    train_data_unit3 = train_data_unit3.to(device)\n",
    "    train_data_unit4 = train_data_unit4.to(device)\n",
    "    train_data_unit5 = train_data_unit5.to(device)\n",
    "\n",
    "    test_data = test_data.to(device)\n",
    "    test_data_unit1 = test_data_unit1.to(device)\n",
    "    test_data_unit2 = test_data_unit2.to(device)\n",
    "    test_data_unit3 = test_data_unit3.to(device)\n",
    "    test_data_unit4 = test_data_unit4.to(device)\n",
    "    test_data_unit5 = test_data_unit5.to(device)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_50\n",
      "training_loss:0.6895923614501953\n",
      "testing_loss:1102277.875\n",
      "epoch_100\n",
      "training_loss:0.41996943950653076\n",
      "testing_loss:1101868.375\n",
      "epoch_150\n",
      "training_loss:0.24827080965042114\n",
      "testing_loss:1101889.5\n",
      "epoch_200\n",
      "training_loss:0.18639397621154785\n",
      "testing_loss:1101895.75\n",
      "epoch_250\n",
      "training_loss:0.15197598934173584\n",
      "testing_loss:1101927.375\n",
      "epoch_300\n",
      "training_loss:0.14125092327594757\n",
      "testing_loss:1101855.25\n",
      "epoch_350\n",
      "training_loss:0.13424722850322723\n",
      "testing_loss:1101807.125\n",
      "epoch_400\n",
      "training_loss:0.1345810443162918\n",
      "testing_loss:1101789.25\n",
      "epoch_450\n",
      "training_loss:0.13104723393917084\n",
      "testing_loss:1101764.875\n",
      "epoch_500\n",
      "training_loss:0.1313045471906662\n",
      "testing_loss:1101754.0\n",
      "epoch_550\n",
      "training_loss:0.12981343269348145\n",
      "testing_loss:1101797.875\n",
      "epoch_600\n",
      "training_loss:0.12960907816886902\n",
      "testing_loss:1101832.375\n",
      "epoch_650\n",
      "training_loss:0.1294720321893692\n",
      "testing_loss:1101843.375\n",
      "epoch_700\n",
      "training_loss:0.13005316257476807\n",
      "testing_loss:1101857.0\n",
      "epoch_750\n",
      "training_loss:0.12933850288391113\n",
      "testing_loss:1101873.375\n",
      "epoch_800\n",
      "training_loss:0.1291152834892273\n",
      "testing_loss:1101891.5\n",
      "epoch_850\n",
      "training_loss:0.12893550097942352\n",
      "testing_loss:1101899.375\n",
      "epoch_900\n",
      "training_loss:0.13010293245315552\n",
      "testing_loss:1101910.125\n",
      "epoch_950\n",
      "training_loss:0.1290970742702484\n",
      "testing_loss:1101918.125\n",
      "epoch_1000\n",
      "training_loss:0.1301146298646927\n",
      "testing_loss:1101929.25\n",
      "epoch_1050\n",
      "training_loss:0.12990716099739075\n",
      "testing_loss:1101935.75\n",
      "epoch_1100\n",
      "training_loss:0.12873737514019012\n",
      "testing_loss:1101937.125\n",
      "epoch_1150\n",
      "training_loss:0.12890754640102386\n",
      "testing_loss:1101936.75\n",
      "epoch_1200\n",
      "training_loss:0.1286894828081131\n",
      "testing_loss:1101941.25\n",
      "epoch_1250\n",
      "training_loss:0.12876878678798676\n",
      "testing_loss:1101946.875\n",
      "epoch_1300\n",
      "training_loss:0.12875793874263763\n",
      "testing_loss:1101942.875\n",
      "epoch_1350\n",
      "training_loss:0.12878116965293884\n",
      "testing_loss:1101945.375\n",
      "epoch_1400\n",
      "training_loss:0.13027073442935944\n",
      "testing_loss:1101944.125\n",
      "epoch_1450\n",
      "training_loss:0.12924377620220184\n",
      "testing_loss:1101936.625\n",
      "epoch_1500\n",
      "training_loss:0.12908343970775604\n",
      "testing_loss:1101938.375\n",
      "epoch_1550\n",
      "training_loss:0.128650963306427\n",
      "testing_loss:1101935.375\n",
      "epoch_1600\n",
      "training_loss:0.12902574241161346\n",
      "testing_loss:1101928.25\n",
      "epoch_1650\n",
      "training_loss:0.12871263921260834\n",
      "testing_loss:1101926.625\n",
      "epoch_1700\n",
      "training_loss:0.12908922135829926\n",
      "testing_loss:1101923.75\n",
      "epoch_1750\n",
      "training_loss:0.12903180718421936\n",
      "testing_loss:1101921.25\n",
      "epoch_1800\n",
      "training_loss:0.1299479603767395\n",
      "testing_loss:1101915.0\n",
      "time span: 108.0152 s\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train()\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500, 33])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "960.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "21120/22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.current_device()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
